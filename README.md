# Contrastively Trained Encodings from Decoder
Cerebral Valley Llama-3 Hackathon 2024 submission.

---
![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)
![Python 3.10](https://img.shields.io/badge/python-3.10-blue.svg)

---
<p align="center">
    <a href="#readme">
        <img alt="CoTrEnD Logo" src="clapt/clapt_rag/static/cotrend.webp" style="height: 256px;">
    </a>
</p>
<h1 align="center" style="font-size: 2.5em; margin: 0; padding: 0;">CoTrEnD</h1>
<p align="center" style="font-size: 1.2em; font-weight: 300; color: #555; margin: 0;">
    Extending Decoders with an Integrated Encoder
</p>

This repo holds the code for training encoders that embed the final hidden state from large decoder models. To our knowledge, CoTrEnD is the first architecture to leverage a contrastive loss to train an encoder from a decoder.

## Team:
#### Abhishek Singh [![LinkedIn](https://img.shields.io/badge/-LinkedIn-blue?style=flat-square&logo=linkedin)](https://www.linkedin.com/in/abhisheksingh-7/) [![GitHub](https://img.shields.io/badge/-GitHub-black?style=flat-square&logo=github)](https://github.com/abhisheksingh-7)

#### Arthur Böök [![LinkedIn](https://img.shields.io/badge/-LinkedIn-blue?style=flat-square&logo=linkedin)](https://www.linkedin.com/in/arthurbook/) [![GitHub](https://img.shields.io/badge/-GitHub-black?style=flat-square&logo=github)](https://github.com/ArthurBook)

#### Wian Stipp  [![LinkedIn](https://img.shields.io/badge/-LinkedIn-blue?style=flat-square&logo=linkedin)](https://www.linkedin.com/in/wian-stipp/) [![GitHub](https://img.shields.io/badge/-GitHub-black?style=flat-square&logo=github)](https://github.com/WianStipp)
